{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom transformers import TFAutoModel, AutoTokenizer\nfrom datasets import load_dataset","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-24T19:14:32.491202Z","iopub.execute_input":"2024-10-24T19:14:32.492142Z","iopub.status.idle":"2024-10-24T19:14:32.496610Z","shell.execute_reply.started":"2024-10-24T19:14:32.492099Z","shell.execute_reply":"2024-10-24T19:14:32.495567Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"model = TFAutoModel.from_pretrained(\"bert-base-uncased\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-24T19:14:32.501676Z","iopub.execute_input":"2024-10-24T19:14:32.502091Z","iopub.status.idle":"2024-10-24T19:14:34.018170Z","shell.execute_reply.started":"2024-10-24T19:14:32.502053Z","shell.execute_reply":"2024-10-24T19:14:34.017268Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFBertModel were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-24T19:14:34.019935Z","iopub.execute_input":"2024-10-24T19:14:34.020313Z","iopub.status.idle":"2024-10-24T19:14:34.132022Z","shell.execute_reply.started":"2024-10-24T19:14:34.020272Z","shell.execute_reply":"2024-10-24T19:14:34.130903Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"inputs = tokenizer(['Hello world', 'Hi how are you shees sheikh ikram'], padding=True, truncation=True,\n                  return_tensors='tf')\ninputs","metadata":{"execution":{"iopub.status.busy":"2024-10-24T19:14:34.134454Z","iopub.execute_input":"2024-10-24T19:14:34.134803Z","iopub.status.idle":"2024-10-24T19:14:34.144602Z","shell.execute_reply.started":"2024-10-24T19:14:34.134766Z","shell.execute_reply":"2024-10-24T19:14:34.143609Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"{'input_ids': <tf.Tensor: shape=(2, 11), dtype=int32, numpy=\narray([[  101,  7592,  2088,   102,     0,     0,     0,     0,     0,\n            0,     0],\n       [  101,  7632,  2129,  2024,  2017,  2016,  2229, 12840, 20912,\n         6444,   102]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(2, 11), dtype=int32, numpy=\narray([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(2, 11), dtype=int32, numpy=\narray([[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)>}"},"metadata":{}}]},{"cell_type":"code","source":"output =model(inputs)\noutput","metadata":{"execution":{"iopub.status.busy":"2024-10-24T19:14:34.147831Z","iopub.execute_input":"2024-10-24T19:14:34.148271Z","iopub.status.idle":"2024-10-24T19:14:34.414532Z","shell.execute_reply.started":"2024-10-24T19:14:34.148204Z","shell.execute_reply":"2024-10-24T19:14:34.413529Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"TFBaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=<tf.Tensor: shape=(2, 11, 768), dtype=float32, numpy=\narray([[[-0.16888325,  0.13606349, -0.13940075, ..., -0.6251125 ,\n          0.0521726 ,  0.3671454 ],\n        [-0.36327422,  0.14121883,  0.8799867 , ...,  0.10433026,\n          0.28875732,  0.37267917],\n        [-0.6985945 , -0.69879687,  0.06450197, ..., -0.2210373 ,\n          0.00986866, -0.5939789 ],\n        ...,\n        [-0.49337777, -0.23890363,  0.29679617, ..., -0.11194012,\n         -0.03332446,  0.00135865],\n        [-0.1550966 , -0.09623349,  0.64029384, ..., -0.22854681,\n         -0.02242169,  0.19605747],\n        [-0.3504956 , -0.09983736,  0.5801807 , ..., -0.18992907,\n         -0.0272956 ,  0.19017054]],\n\n       [[-0.36625385,  0.10113718,  0.0441477 , ..., -0.17761455,\n          0.8079257 ,  0.15100388],\n        [ 0.14330605,  0.31694418,  0.539876  , ..., -0.38345462,\n          1.2116374 , -0.47480512],\n        [-0.70181537, -0.02192725, -0.04889195, ...,  0.01454223,\n          1.0308751 , -0.4557078 ],\n        ...,\n        [-0.09683508, -0.4414258 , -0.15025495, ..., -0.7628866 ,\n          0.31931436,  0.21892115],\n        [-0.28747633, -0.13482323, -0.7269529 , ..., -0.46475983,\n          0.2134636 , -0.5761123 ],\n        [ 0.41725042, -0.09817909, -0.40128055, ...,  0.01414037,\n         -0.4148186 , -0.00804387]]], dtype=float32)>, pooler_output=<tf.Tensor: shape=(2, 768), dtype=float32, numpy=\narray([[-0.90615326, -0.31115294, -0.6216532 , ..., -0.30575174,\n        -0.64009374,  0.9166174 ],\n       [-0.8309885 , -0.49547917, -0.8914442 , ..., -0.6887188 ,\n        -0.72760797,  0.84081805]], dtype=float32)>, past_key_values=None, hidden_states=None, attentions=None, cross_attentions=None)"},"metadata":{}}]},{"cell_type":"code","source":"emotions = load_dataset('SetFit/emotion')\n","metadata":{"execution":{"iopub.status.busy":"2024-10-24T19:14:34.415882Z","iopub.execute_input":"2024-10-24T19:14:34.416236Z","iopub.status.idle":"2024-10-24T19:14:35.023181Z","shell.execute_reply.started":"2024-10-24T19:14:34.416181Z","shell.execute_reply":"2024-10-24T19:14:35.021503Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stderr","text":"Repo card metadata block was not found. Setting CardData to empty.\n","output_type":"stream"}]},{"cell_type":"code","source":"emotions","metadata":{"execution":{"iopub.status.busy":"2024-10-24T19:14:35.024796Z","iopub.execute_input":"2024-10-24T19:14:35.025496Z","iopub.status.idle":"2024-10-24T19:14:35.033441Z","shell.execute_reply.started":"2024-10-24T19:14:35.025445Z","shell.execute_reply":"2024-10-24T19:14:35.032096Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label', 'label_text'],\n        num_rows: 16000\n    })\n    validation: Dataset({\n        features: ['text', 'label', 'label_text'],\n        num_rows: 2000\n    })\n    test: Dataset({\n        features: ['text', 'label', 'label_text'],\n        num_rows: 2000\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"def tokenize(batch):\n    return tokenizer(batch[\"text\"], padding=True, truncation=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-24T19:14:35.034861Z","iopub.execute_input":"2024-10-24T19:14:35.035382Z","iopub.status.idle":"2024-10-24T19:14:35.045117Z","shell.execute_reply.started":"2024-10-24T19:14:35.035320Z","shell.execute_reply":"2024-10-24T19:14:35.043903Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"emotions_encoded = emotions.map(tokenize, batched=True, batch_size=None)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-24T19:14:35.046898Z","iopub.execute_input":"2024-10-24T19:14:35.047425Z","iopub.status.idle":"2024-10-24T19:14:35.083524Z","shell.execute_reply.started":"2024-10-24T19:14:35.047376Z","shell.execute_reply":"2024-10-24T19:14:35.082516Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"emotions_encoded\n","metadata":{"execution":{"iopub.status.busy":"2024-10-24T19:14:35.084821Z","iopub.execute_input":"2024-10-24T19:14:35.085197Z","iopub.status.idle":"2024-10-24T19:14:35.091565Z","shell.execute_reply.started":"2024-10-24T19:14:35.085156Z","shell.execute_reply":"2024-10-24T19:14:35.090268Z"},"trusted":true},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label', 'label_text', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 16000\n    })\n    validation: Dataset({\n        features: ['text', 'label', 'label_text', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 2000\n    })\n    test: Dataset({\n        features: ['text', 'label', 'label_text', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 2000\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"# setting 'input_ids', 'attention_mask', 'token_type_ids', and 'label'\n# to the tensorflow format. Now if you access this dataset you will get these\n# columns in `tf.Tensor` format\n\nemotions_encoded.set_format('tf', \n                            columns=['input_ids', 'attention_mask', 'token_type_ids', 'label'])\n\n# setting BATCH_SIZE to 64.\nBATCH_SIZE = 64\n\ndef order(inp):\n    '''\n    This function will group all the inputs of BERT\n    into a single dictionary and then output it with\n    labels.\n    '''\n    data = list(inp.values())\n    return {\n        'input_ids': data[1],\n        'attention_mask': data[2],\n        'token_type_ids': data[3]\n    }, data[0]\n\n# converting train split of `emotions_encoded` to tensorflow format\ntrain_dataset = tf.data.Dataset.from_tensor_slices(emotions_encoded['train'][:])\n# set batch_size and shuffle\ntrain_dataset = train_dataset.batch(BATCH_SIZE).shuffle(1000)\n# map the `order` function\ntrain_dataset = train_dataset.map(order, num_parallel_calls=tf.data.AUTOTUNE)\n\n# ... doing the same for test set ...\ntest_dataset = tf.data.Dataset.from_tensor_slices(emotions_encoded['test'][:])\ntest_dataset = test_dataset.batch(BATCH_SIZE)\ntest_dataset = test_dataset.map(order, num_parallel_calls=tf.data.AUTOTUNE)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-24T19:14:35.095037Z","iopub.execute_input":"2024-10-24T19:14:35.095421Z","iopub.status.idle":"2024-10-24T19:14:35.400391Z","shell.execute_reply.started":"2024-10-24T19:14:35.095386Z","shell.execute_reply":"2024-10-24T19:14:35.399277Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"inp, out = next(iter(train_dataset)) # a batch from train_dataset\nprint(inp, '\\n\\n', out)","metadata":{"execution":{"iopub.status.busy":"2024-10-24T19:14:35.401885Z","iopub.execute_input":"2024-10-24T19:14:35.402231Z","iopub.status.idle":"2024-10-24T19:14:35.505198Z","shell.execute_reply.started":"2024-10-24T19:14:35.402182Z","shell.execute_reply":"2024-10-24T19:14:35.503976Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"{'input_ids': <tf.Tensor: shape=(64, 87), dtype=int64, numpy=\narray([[ 101, 1045, 2514, ...,    0,    0,    0],\n       [ 101, 1045, 2001, ...,    0,    0,    0],\n       [ 101, 1045, 2071, ...,    0,    0,    0],\n       ...,\n       [ 101, 1045, 2318, ...,    0,    0,    0],\n       [ 101, 1045, 2514, ...,    0,    0,    0],\n       [ 101, 1045, 2514, ...,    0,    0,    0]])>, 'attention_mask': <tf.Tensor: shape=(64, 87), dtype=int64, numpy=\narray([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       ...,\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]])>, 'token_type_ids': <tf.Tensor: shape=(64, 87), dtype=int64, numpy=\narray([[1, 1, 1, ..., 0, 0, 0],\n       [1, 1, 1, ..., 0, 0, 0],\n       [1, 1, 1, ..., 0, 0, 0],\n       ...,\n       [1, 1, 1, ..., 0, 0, 0],\n       [1, 1, 1, ..., 0, 0, 0],\n       [1, 1, 1, ..., 0, 0, 0]])>} \n\n tf.Tensor(\n[1 4 3 1 0 1 0 1 0 5 1 3 0 4 1 3 1 1 1 0 1 0 3 0 0 1 3 0 0 1 1 4 1 5 3 3 1\n 1 4 4 1 1 4 3 3 1 0 4 1 2 4 0 4 4 5 0 1 4 1 0 0 1 4 3], shape=(64,), dtype=int64)\n","output_type":"stream"}]},{"cell_type":"code","source":"class BERTForClassification(tf.keras.Model):\n    \n    def __init__(self, bert_model, num_classes):\n        super().__init__()\n        self.bert = bert_model\n        self.fc = tf.keras.layers.Dense(num_classes, activation='softmax')\n        \n    def call(self, inputs):\n        x = self.bert(inputs)[1]\n        return self.fc(x)","metadata":{"execution":{"iopub.status.busy":"2024-10-24T19:14:35.506776Z","iopub.execute_input":"2024-10-24T19:14:35.509070Z","iopub.status.idle":"2024-10-24T19:14:35.515996Z","shell.execute_reply.started":"2024-10-24T19:14:35.509027Z","shell.execute_reply":"2024-10-24T19:14:35.514695Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"classifier = BERTForClassification(model, num_classes=6)\n\nclassifier.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n    metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-24T19:14:35.517726Z","iopub.execute_input":"2024-10-24T19:14:35.518200Z","iopub.status.idle":"2024-10-24T19:14:35.535556Z","shell.execute_reply.started":"2024-10-24T19:14:35.518151Z","shell.execute_reply":"2024-10-24T19:14:35.534354Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"history = classifier.fit(\n    train_dataset,\n    epochs=3\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-24T19:14:35.537319Z","iopub.execute_input":"2024-10-24T19:14:35.537946Z","iopub.status.idle":"2024-10-24T19:16:42.879541Z","shell.execute_reply.started":"2024-10-24T19:14:35.537898Z","shell.execute_reply":"2024-10-24T19:16:42.878502Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"Epoch 1/3\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1729797291.474103      98 assert_op.cc:38] Ignoring Assert operator bert_for_classification_1_1/tf_bert_model_2/bert/embeddings/assert_less/Assert/Assert\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 144ms/step - accuracy: 0.1065 - loss: 1.9167\nEpoch 2/3\n\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 144ms/step - accuracy: 0.2867 - loss: 1.7168\nEpoch 3/3\n\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 144ms/step - accuracy: 0.3602 - loss: 1.6326\n","output_type":"stream"}]},{"cell_type":"code","source":"classifier.evaluate(test_dataset)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-24T19:16:42.880904Z","iopub.execute_input":"2024-10-24T19:16:42.881277Z","iopub.status.idle":"2024-10-24T19:16:53.180183Z","shell.execute_reply.started":"2024-10-24T19:16:42.881198Z","shell.execute_reply":"2024-10-24T19:16:53.179268Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stderr","text":"W0000 00:00:1729797406.242018      96 assert_op.cc:38] Ignoring Assert operator bert_for_classification_1_1/tf_bert_model_2/bert/embeddings/assert_less/Assert/Assert\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.3588 - loss: 1.6141","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1729797411.659490      99 assert_op.cc:38] Ignoring Assert operator bert_for_classification_1_1/tf_bert_model_2/bert/embeddings/assert_less/Assert/Assert\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 169ms/step - accuracy: 0.3603 - loss: 1.6131\n","output_type":"stream"},{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"[1.5969398021697998, 0.38350000977516174]"},"metadata":{}}]},{"cell_type":"code","source":"def predict_emotion(texts):\n    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors='tf', max_length=128)\n    predictions = classifier(inputs)  # Using the trained classifier model\n    predicted_classes = tf.argmax(predictions, axis=1).numpy()\n    \n    # Emotion labels corresponding to the class indices\n    emotion_labels = ['anger', 'fear', 'joy', 'love', 'sadness', 'surprise']\n    \n    return [emotion_labels[pred] for pred in predicted_classes]","metadata":{"execution":{"iopub.status.busy":"2024-10-24T19:16:53.181424Z","iopub.execute_input":"2024-10-24T19:16:53.181755Z","iopub.status.idle":"2024-10-24T19:16:53.188658Z","shell.execute_reply.started":"2024-10-24T19:16:53.181722Z","shell.execute_reply":"2024-10-24T19:16:53.187424Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"# Function to predict emotion from the model\n\n\n# Sample texts to predict emotions\nsample_texts = [\n    \"I just got a promotion at work! I can't believe how happy I am!\",\n    \"I lost my best friend recently, and I feel so lonely without them.\",\n    \"I am really frustrated with the way they handled the situation.\",\n    \"I can't stop thinking about the dark shadows outside my window.\",\n    \"Every moment spent with you feels like a dream come true.\",\n    \"I was shocked to find out I won the lottery!\"\n]\n\n# Get predictions\npredictions = predict_emotion(sample_texts)\nprint(f'Predicted emotions: {predictions}')\n","metadata":{"execution":{"iopub.status.busy":"2024-10-24T19:16:53.190093Z","iopub.execute_input":"2024-10-24T19:16:53.190430Z","iopub.status.idle":"2024-10-24T19:16:53.314607Z","shell.execute_reply.started":"2024-10-24T19:16:53.190397Z","shell.execute_reply":"2024-10-24T19:16:53.313087Z"},"trusted":true},"execution_count":60,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[60], line 15\u001b[0m\n\u001b[1;32m      5\u001b[0m sample_texts \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI just got a promotion at work! I can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt believe how happy I am!\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI lost my best friend recently, and I feel so lonely without them.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI was shocked to find out I won the lottery!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m ]\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Get predictions\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_texts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted emotions: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredictions\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n","Cell \u001b[0;32mIn[59], line 3\u001b[0m, in \u001b[0;36mpredict_emotion\u001b[0;34m(texts)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_emotion\u001b[39m(texts):\n\u001b[1;32m      2\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m tokenizer(texts, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m'\u001b[39m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Using the trained classifier model\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     predicted_classes \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39margmax(predictions, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Emotion labels corresponding to the class indices\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:753\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    749\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mflatten(args):\n\u001b[1;32m    750\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, KerasTensor) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mis_tensor(\n\u001b[1;32m    751\u001b[0m             arg\n\u001b[1;32m    752\u001b[0m         ):\n\u001b[0;32m--> 753\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    754\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly input tensors may be passed as \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    755\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositional arguments. The following argument value \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    756\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshould be passed as a keyword argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    757\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(arg)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    758\u001b[0m             )\n\u001b[1;32m    760\u001b[0m \u001b[38;5;66;03m# Caches info about `call()` signature, args, kwargs.\u001b[39;00m\n\u001b[1;32m    761\u001b[0m call_spec \u001b[38;5;241m=\u001b[39m CallSpec(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_signature, args, kwargs)\n","\u001b[0;31mValueError\u001b[0m: Only input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: {'input_ids': <tf.Tensor: shape=(6, 20), dtype=int32, numpy=\narray([[  101,  1045,  2074,  2288,  1037,  4712,  2012,  2147,   999,\n         1045,  2064,  1005,  1056,  2903,  2129,  3407,  1045,  2572,\n          999,   102],\n       [  101,  1045,  2439,  2026,  2190,  2767,  3728,  1010,  1998,\n         1045,  2514,  2061,  9479,  2302,  2068,  1012,   102,     0,\n            0,     0],\n       [  101,  1045,  2572,  2428, 10206,  2007,  1996,  2126,  2027,\n         8971,  1996,  3663,  1012,   102,     0,     0,     0,     0,\n            0,     0],\n       [  101,  1045,  2064,  1005,  1056,  2644,  3241,  2055,  1996,\n         2601,  6281,  2648,  2026,  3332,  1012,   102,     0,     0,\n            0,     0],\n       [  101,  2296,  2617,  2985,  2007,  2017,  5683,  2066,  1037,\n         3959,  2272,  2995,  1012,   102,     0,     0,     0,     0,\n            0,     0],\n       [  101,  1045,  2001,  7135,  2000,  2424,  2041,  1045,  2180,\n         1996, 15213,   999,   102,     0,     0,     0,     0,     0,\n            0,     0]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(6, 20), dtype=int32, numpy=\narray([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n      dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(6, 20), dtype=int32, numpy=\narray([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]],\n      dtype=int32)>} (of type <class 'transformers.tokenization_utils_base.BatchEncoding'>)"],"ename":"ValueError","evalue":"Only input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: {'input_ids': <tf.Tensor: shape=(6, 20), dtype=int32, numpy=\narray([[  101,  1045,  2074,  2288,  1037,  4712,  2012,  2147,   999,\n         1045,  2064,  1005,  1056,  2903,  2129,  3407,  1045,  2572,\n          999,   102],\n       [  101,  1045,  2439,  2026,  2190,  2767,  3728,  1010,  1998,\n         1045,  2514,  2061,  9479,  2302,  2068,  1012,   102,     0,\n            0,     0],\n       [  101,  1045,  2572,  2428, 10206,  2007,  1996,  2126,  2027,\n         8971,  1996,  3663,  1012,   102,     0,     0,     0,     0,\n            0,     0],\n       [  101,  1045,  2064,  1005,  1056,  2644,  3241,  2055,  1996,\n         2601,  6281,  2648,  2026,  3332,  1012,   102,     0,     0,\n            0,     0],\n       [  101,  2296,  2617,  2985,  2007,  2017,  5683,  2066,  1037,\n         3959,  2272,  2995,  1012,   102,     0,     0,     0,     0,\n            0,     0],\n       [  101,  1045,  2001,  7135,  2000,  2424,  2041,  1045,  2180,\n         1996, 15213,   999,   102,     0,     0,     0,     0,     0,\n            0,     0]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(6, 20), dtype=int32, numpy=\narray([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n      dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(6, 20), dtype=int32, numpy=\narray([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]],\n      dtype=int32)>} (of type <class 'transformers.tokenization_utils_base.BatchEncoding'>)","output_type":"error"}]},{"cell_type":"code","source":"def predict_emotion(texts, emotion_labels=['anger', 'fear', 'joy', 'love', 'sadness', 'surprise']):\n    # Check if texts are provided\n    if not texts:\n        raise ValueError(\"Input texts cannot be empty.\")\n    \n    # Tokenization\n    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors='tf', max_length=128)\n    \n    # Model Prediction (unpacking inputs as keyword arguments)\n    predictions = classifier(**inputs)  # Unpack the inputs dictionary\n    predicted_classes = tf.argmax(predictions, axis=1).numpy()\n    \n    # Map to emotion labels\n    return [emotion_labels[pred] for pred in predicted_classes]\n\n# Sample usage\nsample_texts = [\n    \"I just got a promotion at work! I can't believe how happy I am!\",\n    \"I lost my best friend recently, and I feel so lonely without them.\",\n    \"I was shocked to find out I won the lottery!\"\n]\n\n# Get predictions\npredictions = predict_emotion(sample_texts)\nprint(f'Predicted emotions: {predictions}')\n","metadata":{"execution":{"iopub.status.busy":"2024-10-24T19:18:35.359873Z","iopub.execute_input":"2024-10-24T19:18:35.360344Z","iopub.status.idle":"2024-10-24T19:18:37.341515Z","shell.execute_reply.started":"2024-10-24T19:18:35.360304Z","shell.execute_reply":"2024-10-24T19:18:37.340074Z"},"trusted":true},"execution_count":61,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[61], line 24\u001b[0m\n\u001b[1;32m     17\u001b[0m sample_texts \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI just got a promotion at work! I can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt believe how happy I am!\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI lost my best friend recently, and I feel so lonely without them.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI was shocked to find out I won the lottery!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     21\u001b[0m ]\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Get predictions\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_texts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted emotions: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredictions\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n","Cell \u001b[0;32mIn[61], line 10\u001b[0m, in \u001b[0;36mpredict_emotion\u001b[0;34m(texts, emotion_labels)\u001b[0m\n\u001b[1;32m      7\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(texts, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m'\u001b[39m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Model Prediction (unpacking inputs as keyword arguments)\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Unpack the inputs dictionary\u001b[39;00m\n\u001b[1;32m     11\u001b[0m predicted_classes \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39margmax(predictions, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Map to emotion labels\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/opt/conda/lib/python3.10/inspect.py:3186\u001b[0m, in \u001b[0;36mSignature.bind\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   3182\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001b[39;00m\n\u001b[1;32m   3183\u001b[0m \u001b[38;5;124;03m    and `kwargs` to the function's signature.  Raises `TypeError`\u001b[39;00m\n\u001b[1;32m   3184\u001b[0m \u001b[38;5;124;03m    if the passed arguments can not be bound.\u001b[39;00m\n\u001b[1;32m   3185\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/inspect.py:3101\u001b[0m, in \u001b[0;36mSignature._bind\u001b[0;34m(self, args, kwargs, partial)\u001b[0m\n\u001b[1;32m   3099\u001b[0m                 msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmissing a required argument: \u001b[39m\u001b[38;5;132;01m{arg!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   3100\u001b[0m                 msg \u001b[38;5;241m=\u001b[39m msg\u001b[38;5;241m.\u001b[39mformat(arg\u001b[38;5;241m=\u001b[39mparam\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m-> 3101\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3102\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3103\u001b[0m     \u001b[38;5;66;03m# We have a positional argument to process\u001b[39;00m\n\u001b[1;32m   3104\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n","\u001b[0;31mTypeError\u001b[0m: missing a required argument: 'inputs'"],"ename":"TypeError","evalue":"missing a required argument: 'inputs'","output_type":"error"}]}]}